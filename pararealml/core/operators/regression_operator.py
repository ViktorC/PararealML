from typing import Union, Tuple, Callable

import numpy as np

from pararealml.core.initial_condition import DiscreteInitialCondition
from pararealml.core.initial_value_problem import InitialValueProblem
from pararealml.core.operator import Operator
from pararealml.core.operators.ml_operator import MLOperator
from pararealml.utils.ml import train_regression_model, RegressionModel, \
    root_mean_squared_error


class RegressionOperator(MLOperator):
    """
    A supervised machine learning operator that uses regression to model
    another operator for solving initial value problems.
    """

    def train(
            self,
            ivp: InitialValueProblem,
            oracle: Operator,
            model: RegressionModel,
            iterations: int,
            noise_sd: Union[float, Tuple[float, float]],
            relative_noise: bool = False,
            test_size: float = .2,
            score_func: Callable[[np.ndarray, np.ndarray], float] =
            root_mean_squared_error
    ) -> Tuple[float, float]:
        """
        Fits a regression model to training data generated by the oracle. The
        inputs of the model are spatio-temporal coordinates and the value of
        the solution at the coordinates and its outputs are the value of the
        solution at the next time step. The training data is generated by
        using the oracle to solve sub-IVPs with randomised initial conditions
        and a time domain extent matching the step size of this operator.

        :param ivp: the IVP to train the regression model on
        :param oracle: the operator providing the training data
        :param model: the model to fit to the training data
        :param iterations: the number of data generation iterations
        :param noise_sd: the standard deviation of the Gaussian noise to add to
            the initial conditions of the sub-IVPs. It can be either a scalar,
            in which case the noise is sampled from the same distribution for
            each sub-IVP, or a tuple of two values. The first value of the
            tuple is the standard deviation of the distribution from which the
            noise added to the first sub-IVP is sampled and the second value of
            the tuple is the standard deviation of the distribution from which
            the noise added to the last sub-IVP is sampled. The standard
            deviations of the distribution associated with the sub-IVPs in
            between are calculated using linear interpolation.
        :param relative_noise: whether the noise standard deviation is relative
            to the value of the initial conditions of the sub-IVPs
        :param test_size: the fraction of all data points that should be used
            for testing
        :param score_func: the prediction scoring function to use
        :return: the training and test losses
        """
        if iterations <= 0:
            raise ValueError

        if isinstance(noise_sd, (tuple, list)):
            if len(noise_sd) != 2:
                raise ValueError
            if noise_sd[0] < 0. or noise_sd[1] < 0.:
                raise ValueError
        else:
            if not isinstance(noise_sd, float):
                raise ValueError
            if noise_sd < 0.:
                raise ValueError

            noise_sd = (noise_sd, noise_sd)

        cp = ivp.constrained_problem
        diff_eq = cp.differential_equation

        n_spatial_points = np.prod(cp.mesh.shape(self._vertex_oriented)) \
            if diff_eq.x_dimension else 1

        time_points = self._discretise_time_domain(ivp.t_interval, self._d_t)
        last_sub_ivp_start_time_point = len(time_points) - 2

        x_batch = self._create_input_batch(cp, time_points[:-1])
        x_batch = np.concatenate(
            (x_batch, np.empty((x_batch.shape[0], diff_eq.y_dimension))),
            axis=-1)
        all_x = np.tile(x_batch, (iterations, 1))

        y_0 = ivp.initial_condition.discrete_y_0(self._vertex_oriented)
        all_y = np.empty((all_x.shape[0], diff_eq.y_dimension))

        for epoch in range(iterations):
            offset = epoch * x_batch.shape[0]
            y_i = y_0

            for i, t_i in enumerate(time_points[:-1]):
                if len(time_points) > 2:
                    interpolated_noise_sd = \
                        (noise_sd[0] * (last_sub_ivp_start_time_point - i) +
                         noise_sd[1] * i) / last_sub_ivp_start_time_point
                else:
                    interpolated_noise_sd = noise_sd[0]
                if relative_noise:
                    interpolated_noise_sd = np.abs(y_i * interpolated_noise_sd)

                y_i += np.random.normal(
                    loc=0.,
                    scale=interpolated_noise_sd,
                    size=y_i.shape).astype(y_i.dtype)

                time_point_offset = offset + i * n_spatial_points
                all_x[time_point_offset:time_point_offset + n_spatial_points,
                      -diff_eq.y_dimension:] = \
                    y_i.reshape((-1, diff_eq.y_dimension))

                sub_ivp = InitialValueProblem(
                    cp,
                    (t_i, t_i + self._d_t),
                    DiscreteInitialCondition(cp, y_i, self._vertex_oriented))
                solution = oracle.solve(sub_ivp)

                y_i = solution.discrete_y(self._vertex_oriented)[-1, ...]
                all_y[time_point_offset:time_point_offset + n_spatial_points,
                      :] = y_i.reshape((-1, diff_eq.y_dimension))

        train_score, test_score = train_regression_model(
            model, all_x, all_y, test_size, score_func)
        self._model = model

        return train_score, test_score
